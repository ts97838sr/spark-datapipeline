<?xml version="1.0" encoding="UTF-8" ?>
<root>
    <TASK_PROJECT>TEST_JSON_INPUT</TASK_PROJECT>
    <WF_STATUS>A</WF_STATUS>
    <LOG_LOCATION>/Users/tamalsarkar/IdeaProjects/spark-datapipeline/config_param/log/TEST_JSON_INPUT.log</LOG_LOCATION>
    <TASK_NAME>
        <TASK_NAME>INPUT_DF</TASK_NAME>
        <TASK_KEY>FileRead</TASK_KEY>
        <TASK_CATEGORY>input</TASK_CATEGORY>
        <TASK_VALUE>
            <TYPE>csv</TYPE>
            <PARAM>
                <Key>path</Key>
                <value>/Users/tamalsarkar/IdeaProjects/spark-datapipeline/config_param/input.csv</value>
            </PARAM>
            <PARAM>
                <Key>Separator</Key>
                <value>,</value>
            </PARAM>
        </TASK_VALUE>
        <START_TS>CURRENT_TIMESTAMP</START_TS>
        <UPDATED_BY>TAMAL</UPDATED_BY>
    </TASK_NAME>
    <TASK_NAME>
        <TASK_NAME>TABLE_DF</TASK_NAME>
        <TASK_KEY>TableUnload</TASK_KEY>
        <TASK_CATEGORY>DBRead</TASK_CATEGORY>
        <TASK_VALUE>
            <TYPE>postgresql</TYPE>
            <CONFIG_LOC>/Users/tamalsarkar/IdeaProjects/spark-datapipeline/config_param/configDir/wfConfig.ini</CONFIG_LOC>
            <PARAM>
                <Key>table</Key>
                <value>users</value>
            </PARAM>
        </TASK_VALUE>
        <START_TS>CURRENT_TIMESTAMP</START_TS>
        <UPDATED_BY>TAMAL</UPDATED_BY>
    </TASK_NAME>
    <TASK_NAME>
        <TASK_NAME>ACCOUNT_DF</TASK_NAME>
        <TASK_KEY>TableUnload</TASK_KEY>
        <TASK_CATEGORY>DBRead</TASK_CATEGORY>
        <TASK_VALUE>
            <TYPE>postgresql</TYPE>
            <CONFIG_LOC>/Users/tamalsarkar/IdeaProjects/spark-datapipeline/config_param/configDir/wfConfig.ini</CONFIG_LOC>
            <PARAM>
                <Key>query</Key>
                <value>(select id,name,balance from accounts) as tbl1</value>
            </PARAM>
        </TASK_VALUE>
        <START_TS>CURRENT_TIMESTAMP</START_TS>
        <UPDATED_BY>TAMAL</UPDATED_BY>
    </TASK_NAME>
    <TASK_NAME>
        <TASK_NAME>TRANSFORM_DF1</TASK_NAME>
        <TASK_CATEGORY>transform</TASK_CATEGORY>
        <TASK_KEY>DataTransform</TASK_KEY>
        <TASK_VALUE>
            <TYPE>sql</TYPE>
            <PARAM>
                <Key>query</Key>
                <Value>SELECT id,firstname,lastname,address from INPUT_DF where id in (1,2,3)</Value>
            </PARAM>
            <PARAM>
                <Key>Cache</Key>
                <Value>True</Value>
            </PARAM>
        </TASK_VALUE>
        <START_TS>CURRENT_TIMESTAMP</START_TS>
        <UPDATED_BY>TAMAL</UPDATED_BY>
    </TASK_NAME>
    <TASK_NAME>
        <TASK_NAME>TRANSFORM_DF2</TASK_NAME>
        <TASK_CATEGORY>transform</TASK_CATEGORY>
        <TASK_KEY>DataTransform</TASK_KEY>
        <TASK_VALUE>
            <TYPE>sql</TYPE>
            <PARAM>
                <Key>query</Key>
                <Value>SELECT TRANSFORM_DF1.firstname,TRANSFORM_DF1.lastname,TABLE_DF.name,TABLE_DF.email,TABLE_DF.address from TRANSFORM_DF1 INNER JOIN TABLE_DF ON TRANSFORM_DF1.id=TABLE_DF.id</Value>
            </PARAM>
            <PARAM>
                <Key>Cache</Key>
                <Value>False</Value>
            </PARAM>
        </TASK_VALUE>
        <START_TS>CURRENT_TIMESTAMP</START_TS>
        <UPDATED_BY>TAMAL</UPDATED_BY>
    </TASK_NAME>
    <TASK_NAME>
        <TASK_NAME>TRANSFORM_DF3</TASK_NAME>
        <TASK_CATEGORY>transform</TASK_CATEGORY>
        <TASK_KEY>DataTransform</TASK_KEY>
        <TASK_VALUE>
            <TYPE>sql</TYPE>
            <PARAM>
                <Key>query</Key>
                <Value>SELECT TRANSFORM_DF2.firstname,TRANSFORM_DF2.lastname,ACCOUNT_DF.name,ACCOUNT_DF.balance,TRANSFORM_DF2.email,TRANSFORM_DF2.address from TRANSFORM_DF2 INNER JOIN ACCOUNT_DF ON TRANSFORM_DF2.name=ACCOUNT_DF.name</Value>
            </PARAM>
            <PARAM>
                <Key>Cache</Key>
                <Value>False</Value>
            </PARAM>
        </TASK_VALUE>
        <START_TS>CURRENT_TIMESTAMP</START_TS>
        <UPDATED_BY>TAMAL</UPDATED_BY>
    </TASK_NAME>
    <TASK_NAME>
        <TASK_NAME>OUTPUT_DF</TASK_NAME>
        <TASK_CATEGORY>output</TASK_CATEGORY>
        <TASK_KEY>FileWrite</TASK_KEY>
        <TASK_VALUE>
            <TYPE>csv</TYPE>
            <INPUT>TRANSFORM_DF3</INPUT>
            <PARAM>
                <Key>path</Key>
                <value>/Users/tamalsarkar/IdeaProjects/spark-datapipeline/output</value>
            </PARAM>
            <PARAM>
                <Key>header</Key>
                <value>True</value>
            </PARAM>
            <PARAM>
                <Key>repartition</Key>
                <value>1</value>
            </PARAM>
        </TASK_VALUE>
        <START_TS>CURRENT_TIMESTAMP</START_TS>
        <UPDATED_BY>TAMAL</UPDATED_BY>
    </TASK_NAME>
    <TASK_NAME>
        <TASK_NAME>TableWrite</TASK_NAME>
        <TASK_KEY>tableLoad</TASK_KEY>
        <TASK_CATEGORY>DBWrite</TASK_CATEGORY>
        <TASK_VALUE>
            <TYPE>postgresql</TYPE>
            <CONFIG_LOC>/Users/tamalsarkar/IdeaProjects/spark-datapipeline/config_param/configDir/wfConfig.ini</CONFIG_LOC>
            <PARAM>
                <Key>table</Key>
                <value>TRANSFORM_DF3</value>
            </PARAM>
        </TASK_VALUE>
        <START_TS>CURRENT_TIMESTAMP</START_TS>
        <UPDATED_BY>TAMAL</UPDATED_BY>
    </TASK_NAME>
</root>